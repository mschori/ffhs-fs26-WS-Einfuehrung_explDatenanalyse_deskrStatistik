---
title: "Kombinatorik und Wahrscheinlichkeitsrechnung"
format: html
---

# Grundbegriffe der Wahrscheinlichkeitsrechnung

- Zufallsvorgang: Wiederholbares und zufÃ¤lliges Ereigniss
- Zufallsexperimente: DurchgefÃ¼hrter Zufallsvorgang
- Ergebnismenge: Alle mÃ¶glichen Ergebnisse, die ein Ereignis annehmen kann
  - Bei einem WÃ¼rfel wÃ¤re das: E = {1, 2, 3, 4, 5, 6}
- Ereignis: Ein einzelnes Ereignis in der Ereignismenge
- LaPlace: p = Anzahl der mÃ¶glichen Ereignisse / die Anzahl aller Ereignisse
  - Das gilt, wenn alle Ergebnisse gleich wahrscheinlich sind
  - Bei einem WÃ¼rfel wÃ¤re die Wahrscheinlichkeit, dass eine 2 gewÃ¼rfelt wird: p = 1 / 6
  - Die Wahrscheinlichkeit, dass eine 1 oder eine 4 gewÃ¼rfelt ist: p = 2 / 6 = 1 / 3
- $A \cap B$: Der Schnitt. EnthÃ¤lt alle Ergebnisse, die in beiden Ereignissen liegen
- $A \cup B$: Die Vereinigung. EnthÃ¤lt alles, was in mindestens einem der Ereignisse liegt
- $A \setminus B$: Die Differenz. EnthÃ¤lt alles, was in A liegt, aber nicht in B
- $A^c$: Das Komplement. EnthÃ¤lt alles, was nicht in A liegt
- Venn-Diagramm: Geometrische Darstellung der Mengenbeziehung
- Axiomatische Definition: saubere mathematische Grundlage (Kolmogorow). Eine Wahrscheinlichkeit ist eine Funktion P, die drei Bedingungen erfÃ¼llt:
  - NichtnegativitÃ¤t: $P(A) \geq 0$
  - Normierung: $P(\Omega) = 1$
  - AdditivitÃ¤t fÃ¼r disjunkte Ereignisse
- Komplementregel: $P(A^c) = 1 - P(A)$
- Vereinigung zweier Ereignisse: $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
- Differenz: $P(A \setminus B) = P(A) - P(A \cap B)$

![Venn-Diagramm Beispiel](images/venn-diagramm-beispiel.webp)

# ğŸ“Œ Kombinatorik & Stichproben (Kapitel 11.2)
## 0. Fundamentalprinzip
Erster Sachverhalt: n<sub>1</sub>
Zweiter Sachverhalt: n<sub>2</sub>
Beide Sachverhalte: n<sub>1</sub> x n<sub>2</sub>
2 Donuts und 3 Glasuren ergibt 2 x 3 = 6 mÃ¶gliche Donut-Varianten.
Das geht immer weiter: also wenn noch ein Toping (3 Arten) dazu kommt = 2 x 3 x 3 = 18

## 1. Permutationen â€“ Anordnungen von Objekten
**Permutation** = Anordnung aller Elemente einer Menge in einer bestimmten Reihenfolge.

Beispiel: 
Menge {A, B, C}  
MÃ¶gliche Anordnungen: ABC, ACB, BAC, BCA, CAB, CBA â†’ 6 StÃ¼ck.

**Allgemein:**  
FÃ¼r **N** verschiedene Objekte gibt es N!=1â‹…2â‹…3â‹…â‹¯â‹…N Permutationen.

- 3! = 6
- 4! = 24
- 5! = 120  
    usw.

! bedeutet FakultÃ¤t

> Merksatz: _Permutation = alles verwenden, Reihenfolge wichtig._

---

## 2. Urnenmodell und Stichproben-Arten

Wir denken uns eine **Urne mit N nummerierten Kugeln**.<br>  
Wir ziehen **n** Kugeln.  <br>
Es gibt vier Varianten â€“ Kombination der Fragen:

1. **Mit oder ohne ZurÃ¼cklegen?**
2. **Reihenfolge wichtig oder egal?**

### 2.1 Mit / Ohne ZurÃ¼cklegen

- **Mit ZurÃ¼cklegen:**  
    Gezogene Kugel kommt wieder zurÃ¼ck â†’ gleiche Auswahlbasis bei jedem Zug.
- **Ohne ZurÃ¼cklegen:**  
    Gezogene Kugel bleibt draussen â†’ Grundgesamtheit wird kleiner.

Beispiele:

- Lotto: **ohne ZurÃ¼cklegen**
- Mehrfacher MÃ¼nzwurf: **mit ZurÃ¼cklegen** (Zahl/Kopf â€kommen wieder reinâ€œ)

---

### 2.2 Mit / Ohne BerÃ¼cksichtigung der Reihenfolge

- **Reihenfolge wichtig:** geordnete Auswahl  
    (z. B. 1. Platz, 2. Platz, 3. Platz)
- **Reihenfolge unwichtig:** ungeordnete Auswahl  
    (z. B. welche 6 Zahlen aus 49 wurden gezogen â€“ Reihenfolge egal)

---

## 3. Die vier FÃ¤lle (Formeln)

Sei **N** = Anzahl Elemente in der Grundgesamtheit und **n** = Anzahl gezogener Elemente.

### 3.1 Ziehen **ohne ZurÃ¼cklegen**, Reihenfolge **wichtig**

Hier entstehen **Variationen ohne Wiederholung**.

#### $\text{Anzahl} = \frac{N!}{(N-n)!}$

Beispiel (Olympia, 100m-Finale):<br>
8 LÃ¤ufer, 3 Medaillen â†’ N=8, n=3

#### $\frac{8!}{(8-3)!} = \frac{8!}{5!} = 8 \cdot 7 \cdot 6 = 336$

---

### 3.2 Ziehen **mit ZurÃ¼cklegen**, Reihenfolge **wichtig**

Jeder Zug hat wieder N MÃ¶glichkeiten.

Anzahl=N<sup>n</sup>

Beispiel (2 WÃ¼rfel, farblich unterschieden):<br>
N = 6<br>
n = 2 <br>
Berechnung: 6Â² = 36 mÃ¶gliche Paare (1,1)â€¦(6,6)

---

### 3.3 Ziehen **ohne ZurÃ¼cklegen**, Reihenfolge **egal**

Das sind **Kombinationen ohne Wiederholung**.

#### $\text{Anzahl} = \binom{N}{n} = \frac{N!}{(N-n)! \cdot n!}$

Beispiel (deutsches Lotto â€6 aus 49â€œ):

#### $\binom{49}{6} = \frac{49!}{43! \cdot 6!} = 13\,983\,816$

---

### 3.4 Ziehen **mit ZurÃ¼cklegen**, Reihenfolge **egal**

Formel (aus dem Buch, ohne Herleitung):

#### $\text{Anzahl} = \binom{N + n - 1}{n} = \frac{(N+n-1)!}{(N-1)! \cdot n!}$

Beispiel:<br>  
3 Kandidaten Bâ‚,Bâ‚‚,Bâ‚ƒ, auf einem Wahlzettel werden 2 Kreuze vergeben,  <br>
auch doppelt beim gleichen Kandidaten erlaubt.  <br>
â†’ N = 3, n = 2

#### $\binom{3+2-1}{2} = \binom{4}{2} = 6$! (also 6 * 5 * 4 * 3 * 2 * 1)

---

## 4. Stichproben-Arten (sprachlich)

**Stichprobe** = Auswahl von n Elementen aus N.

Begrifflich kann man sagen:

- _Stichprobe mit ZurÃ¼cklegen_
- _Stichprobe ohne ZurÃ¼cklegen_
- _geordnete Stichprobe_ (Reihenfolge wichtig)
- _ungeordnete Stichprobe_ (Reihenfolge egal)

Wenn â€jede mÃ¶gliche Stichprobe gleicher Art die gleiche Wahrscheinlichkeit hatâ€œ, spricht man von einer **einfachen Zufallsstichprobe**.

# ğŸ“Œ Bedingte Wahrscheinlichkeit & UnabhÃ¤ngigkeit

## 1. Bedingte Wahrscheinlichkeit â€“ was bedeutet das?

Eine **bedingte Wahrscheinlichkeit** beschreibt die Wahrscheinlichkeit eines Ereignisses **unter der Voraussetzung**, dass ein anderes Ereignis bereits eingetreten ist.

Notation: $P(A \mid B)$<br>
= Wahrscheinlichkeit fÃ¼r A **gegeben**, dass B bereits eingetreten ist.

### Definition (Laplace-Sicht)

#### $P(A \mid B) = \frac{\text{Anzahl der fÃ¼r } A \cap B \text{ gÃ¼nstigen Ergebnisse}} {\text{Anzahl der fÃ¼r } B \text{ gÃ¼nstigen Ergebnisse}}$

### Allgemeine Formel (Kolmogorow)

#### $P(A \mid B) = \frac{P(A \cap B)}{P(B)}$

> Der Nenner P(B) muss > 0 sein (sonst ist die Bedingung sinnlos).

---

## 2. Zusammenhang zwischen zwei bedingten Wahrscheinlichkeiten

Aus der Definition folgt:

#### $P(A \cap B) = P(A \mid B)\,P(B)$

und symmetrisch:

#### $P(A \cap B) = P(B \mid A)\,P(A)$

Daraus ergibt sich der **Satz von Bayes**:

#### $P(A \mid B) = \frac{P(B \mid A)\,P(A)}{P(B)}$

---

## 3. AbhÃ¤ngige vs. unabhÃ¤ngige Ereignisse

### AbhÃ¤ngigkeit

A und B sind **abhÃ¤ngig**, wenn das Wissen Ã¼ber das eine Ereignis die Wahrscheinlichkeit des anderen **verÃ¤ndert**.

Beispiel: P(B) â‰  P(B | A)

### UnabhÃ¤ngigkeit

A und B sind **unabhÃ¤ngig**, wenn sich die Wahrscheinlichkeiten nicht beeinflussen.

Formale Definition:

#### $P(A \mid B) = P(A) \quad\text{und}\quad P(B \mid A) = P(B)$

Damit folgt:

#### $P(A \cap B) = P(A)\,P(B)$

> Diese Gleichung ist das wichtigste Erkennungsmerkmal fÃ¼r UnabhÃ¤ngigkeit.

Beispiel:  <br>
Zweimaliger MÃ¼nzwurf â†’ Ergebnis des ersten Wurfs beeinflusst nicht das zweite.

---

## 4. Multiplikationssatz (Produktregel)

Der Multiplikationssatz beschreibt, wie man **Schnittwahrscheinlichkeiten** berechnet.

### Allgemeiner Multiplikationssatz

#### $P(A \cap B) = P(A \mid B)\,P(B)$

Immer gÃ¼ltig, egal ob abhÃ¤ngig oder unabhÃ¤ngig.

### Multiplikationssatz fÃ¼r unabhÃ¤ngige Ereignisse

Wenn A und B unabhÃ¤ngig sind:

#### $P(A \cap B) = P(A)\,P(B)$

Das ist die oft verwendete Form, z. B. bei MÃ¼nzwÃ¼rfen, WÃ¼rfeln oder technischen Bauteilen mit unabhÃ¤ngigen Ausfallwahrscheinlichkeiten.

---

## 5. Interpretation fÃ¼r Anwendungen

- **Bedingte Wahrscheinlichkeit**:  
    _Wie groÃŸ ist die Chance fÃ¼r A, wenn wir wissen, dass B bereits eingetreten ist?_
- **AbhÃ¤ngigkeit**:  
    Das Eintreten des einen Ereignisses verÃ¤ndert die Wahrscheinlichkeit des anderen.
- **UnabhÃ¤ngigkeit**:  
    Das Wissen Ã¼ber B bringt **keine** zusÃ¤tzliche Information Ã¼ber A.
- **Multiplikationssatz**:  
    Nutzt man immer, wenn man etwas wie â€A und B passieren gleichzeitigâ€œ berechnen will.

# ğŸ“Œ SensitivitÃ¤t & SpezifitÃ¤t

## 1. Grundidee

Bei medizinischen Tests unterscheidet man zwischen zwei Ebenen:

- **tatsÃ¤chlicher Gesundheitszustand** (wahr krank / wahr gesund)
- **Testergebnis** (Test positiv / Test negativ)

Daraus entstehen _vier_ FÃ¤lle in einer Vierfeldertafel:

|Test positiv|Test negativ|
|---|---|---|
|**tatsÃ¤chlich krank**|richtig-positiv (_rp_)|falsch-negativ (_fn_)|
|**tatsÃ¤chlich gesund**|falsch-positiv (_fp_)|richtig-negativ (_rn_)|

Diese vier Felder sind die Grundlage fÃ¼r SensitivitÃ¤t und SpezifitÃ¤t.

---

## 2. SensitivitÃ¤t

### ğŸ“Œ Definition

#### $\text{SensitivitÃ¤t} = P(\text{Test positiv} \mid \text{tatsÃ¤chlich krank}) = \frac{rp}{rp + fn}$

### Bedeutung:

- Wie **empfindlich** ist der Test gegenÃ¼ber Erkrankten?
- Wie gut erkennt der Test die **Kranken** korrekt?

Eine hohe SensitivitÃ¤t â‡’ _wenig Ã¼bersehene Kranke_.

Beispiel: 99% SensitivitÃ¤t bedeutet:  
99 von 100 wirklich kranken Personen werden erkannt.

---

## 3. SpezifitÃ¤t

### ğŸ“Œ Definition

#### $\text{SpezifitÃ¤t} = P(\text{Test negativ} \mid \text{tatsÃ¤chlich gesund}) = \frac{rn}{fp + rn}$

### Bedeutung:

- Wie gut erkennt der Test die **Gesunden** korrekt?
- Wie gut vermeidet der Test **Fehlalarme**?

Hohe SpezifitÃ¤t â‡’ _wenig falsch-positive Ergebnisse_.

Beispiel: 99% SpezifitÃ¤t bedeutet:<br>  
1 von 100 gesunden Personen erhÃ¤lt fÃ¤lschlicherweise ein positives Testergebnis.

---

## 4. Fehlalarmrate

Aus der SpezifitÃ¤t folgt:

#### $\text{Fehlalarmrate} = \frac{fp}{fp + rn} = 1 - \text{SpezifitÃ¤t}$

Interpretation:  

Anteil der **gesunden** Personen, die fÃ¤lschlicherweise als â€krankâ€œ getestet werden.

---

## 5. Wichtige Interpretation (Fallstrick!)

Auch wenn ein Test **hohe SensitivitÃ¤t UND hohe SpezifitÃ¤t** hat, ist damit **nicht garantiert**, dass ein positives Testergebnis eine hohe Wahrscheinlichkeit fÃ¼r â€tatsÃ¤chlich krankâ€œ bedeutet.

DafÃ¼r ist zusÃ¤tzlich die **PrÃ¤valenz** entscheidend (Anteil der Kranken in der BevÃ¶lkerung).

Beispiel aus dem Buch:

- SensitivitÃ¤t = 99%
- SpezifitÃ¤t = 99%
- PrÃ¤valenz = 1%

â†’ Trotz sehr guter TestqualitÃ¤t ist:<br>
#### $P(\text{tatsÃ¤chlich krank} \mid \text{Test positiv}) \approx 50\%$

Das heiÃŸt: Die HÃ¤lfte aller positiv Getesteten ist trotzdem gesund.